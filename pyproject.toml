[project]
name = "qwen-prompt-expander"
description = "Local AI prompt generator using Qwen/SmolLM2 models. 100% offline and private. Supports 4-bit/8-bit quantization. Runs on 6GB VRAM GPUs alongside Stable Diffusion. Smart token management, Polish-English translation, embedding support, OOM protection."
version = "1.0.0"
license = {file = "LICENSE"} 
# classifiers = [
#     # For OS-independent nodes (works on all operating systems)
#     "Operating System :: OS Independent",
#
#     # OR for OS-specific nodes, specify the supported systems:
#     "Operating System :: Microsoft :: Windows",  # Windows specific
#     "Operating System :: POSIX :: Linux",  # Linux specific
#     "Operating System :: MacOS",  # macOS specific
#
#     # GPU Accelerator support. Pick the ones that are supported by your extension.
#     "Environment :: GPU :: NVIDIA CUDA",    # NVIDIA CUDA support
#     "Environment :: GPU :: AMD ROCm",       # AMD ROCm support
#     "Environment :: GPU :: Intel Arc",      # Intel Arc support
#     "Environment :: NPU :: Huawei Ascend",  # Huawei Ascend support
#     "Environment :: GPU :: Apple Metal",    # Apple Metal support
# ]

dependencies = ["# Translation support (MarianMT)", "sentencepiece", "sacremoses", "# Model optimization", "accelerate", "# Quantization support (4-bit/8-bit)", "bitsandbytes>=0.43.1"]

[project.urls]
Repository = "https://github.com/AnonBOTpl/ComfyUI-Qwen-Prompt-Expander"
#  Used by Comfy Registry https://registry.comfy.org
Documentation = "https://github.com/AnonBOTpl/ComfyUI-Qwen-Prompt-Expander/wiki"
"Bug Tracker" = "https://github.com/AnonBOTpl/ComfyUI-Qwen-Prompt-Expander/issues"

[tool.comfy]
PublisherId = ""
DisplayName = "ComfyUI-Qwen-Prompt-Expander"
Icon = ""
includes = [] 
# "requires-comfyui" = ">=1.0.0"  # ComfyUI version compatibility

